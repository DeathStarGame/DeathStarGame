Continuation of:

- [../cloud-native-system/design.md](../cloud-native-system/design.md)
- [../search-for-the-game.md](../search-for-the-game.md)
- [../origin-cluster/origin-cluster.md](../origin-cluster/origin-cluster.md)
- [../as-vscode-extension.md](../deathstar.ltee/as-vscode-extension.md)
- [../deathstar.ltee/design-notes.md](../deathstar.ltee/design-notes.md)
- [../play-scenarios-in-browser/design-notes.md](../play-scenarios-in-browser/design-notes.md)

## deathstar design

<img height="512px" src="../play-scenarios-in-browser/svg/2020-10-26-IPFS-peers.svg"></img>

- app is some form of desktop instance with an IPFS node included
- IPFS node provides networking and idenetity
- through IPFS node we discover other peers, connect to host peers and bidirectionally exchange data
- the UI runs either in browser or in a webrenderer of a desktop app - so web ui in every case
- docker-to-desktop-app exists?  "take this docker compose deploymen and turn into installable updatable app" ?
  - if exists, app can have browser GUI over rsocket (it's just a renderer)
- app has a jvm-app that is always non-binary so that eval works - this app hosts games
- updates : app or deployment should be installable and auto-updatable
- app comes with: IPFS node, jvm-app, ui
- delivery with docker app: build, share, and run a set of microservices as a single entity
  - users will need to install docker, and docker app plugin
  - then, with a single command install an app (or another instance of it) `docker app install myuser/hello-world:0.1.0 --set hello.port=8181`
  - app ui will notify user about updates and show two commands: one to run a new version of an app, and another (after) to uninstall the previous

## stage 1

- add 
  - traefik (serves ui, proxies rsocket to app directly, serves IPFS node ui)
  - ui-prod ui-dev (dev only builds, ui-prod always serves)
  - jvm-app (has rsocket and can talk to ui)
  - IPFS node (just runs on it's own at this point and we can access it's ui via traefik)
- make this one instance launchable: we launch everything, then jvm-app manually
- make several named instances launchable, such that we only toggle jvm-app 

## stage 2

- explore IPFS node

## one way to develop system and scenarios

- developer or not - there should be a unified single way to develop sceanrios
- and naturally, we developers want to develop them within the system (so we start the whole thing and we can delop it and/or scenarios)
- so what we do it build Death Star game, the same process should be exposed to any user if they want to develop their scenarios (choose only how many player instances to launch in docker)
- but, it should be so that they can use their own repositories - or, simply be able once done to take files and put them themselves wherever
- and the system can download sceanrios from any git repo
- so one system, one way to build it and scenarios within it, so anybody is a user/palyer/developer

## with one system, should browser vscode be in its own tab and game gui in its own?

- if so, VSCode will have a minimal extension for it that will carry out ops originating from jvm-app
- jvm-app and vscode may even share a filesystem inside a docker volume
- jvm-app will say to extension "open this and that file for the user" or say "show timer" or may ask "give me that file" (if they don't share fs, otherwise jvm-app will read itlsef, which is preferable)
- users can download files they edit with browser vscode within the system
- and game GUI will be a standalone app communicating with jvm-app to show scenario's graphics and multiplayer etc.

<img height="512px" src="./svg/2020-10-31-IPFS+vscode.svg"></img>

- IPFS nodes are *both* connected to global peer network and local docker network so that the system can be run even offline
  - IPFS node adds a locally resolvable docker network address to the list of default (auto generated by node addresses)
  - even if laptop is offline or elsewise, nodes still discover each other and multiplayer works


## OS windows for seeing the editor and game gui simulteneously?

- open game gui tab in the brower tab in a new browser window taking half-screen (rigth side)
- open editor tab in another browser window taking the left side of the scree
- drag middle boudary to make one or another bigger
- why
  - if we build our game ui and editor as part of it, we dicard all existing tooling and we'll need to make an editor,clj extension, repl
  - can we leverage the fact that editors exist and build on that? e.g. by using vscode-in-the-browser
  - from user experience standpoint: it is almost the same as having our own tabs and windows inside our ui, whereas OS level windows do exactly that
  - another: links and decoupling from single-ui/single tool
  - although ui runs on localhost, links like `game/player/stats/?whatever=3` should be exchangable ideally, like it already works on the web
  - in the game, such link can be part of a another app's ui and will eventually result in a global decentralzied query (or local for starters) and any peer will see the resulting page, so links would work
- if we use browser tabs themselves as tabs, we can rely on link and think in terms of apps
- it's a different way to look at it: we don't build a single ui, but rather a docker system with possible several uis (we already have IPFS ui, game ui)
- in simpler words
  - players will edit code -> that will go to jvm-app -> and it will push state to game gui
  - so although we use two browser windows by means of splitting PC's screen, we input into the same app entity

## source code of the system (DeathStarGame repo) shared between containers? 

- VScode container and jvm-app preferably should share a filesystem, so that only jvm-app did all fs writes
- another thing - when the system runs, ideally, it should be possible to REPL into it using its own VScode browser ui, and for that the source code should come with the system
- another case - when traefik, IPFS , ui-prod ... etc. containers will be lauchned, they will need to access the config files (which are usually COPYd into on image build or passed as docker-compose env variables)
- but what if it was possible to give all caontainers access to a volume of sorts, that would contain the source - github.com/DeathStarGame/DeathStarGame - a central singular instance of all source
- than, every container could access it's config from this root directory (via volume) , and there would be no need to COPY it in every Dockerfile
- can the dev/prod separation be avoided and can the system come as an OS of sorts?
- this way, the ui build container (with shadow-cljs) could output files as is into respective out dirs within DeathStarGame repo tree, and ui-prod could serve that path directly, no need for copying
- another approach: single container with scripts to start/stop binaries (can even consider a scripting alternative to bash as with a container it's a trivial apt install)

## running the system inside a single container

- first of all, it works (no docker-compose files, restart:always and container tools, but scripts instead)
- it works with giving repo as a volume to several containers( ok that build will override files ,.user dirs will be shared),apps will point to the same src code, so restarting apps ok
- needed an alternative to bash - a lisp, preferably clojure - so that all scripts (even in f files when docking containers) were in a sane language
- with one container, we lose cloud tools and have to script, but gain a bit more flexibility(programmability) and a sort of simplicity/singularity
- bash alternative: only if it has *interoperability* with bash, such that we translate bash examples in docs back and forth without guessing

## distinct builder and runner docker-compose services(containers)

- one builder will run shadow-cljs that will compile both ui and vscode extension
- another will build uberjar which will be run from a slimmer jre-only container in release version (if ran without REPLs into system itself)
- all services will share a volume (DeathStarGame repo), builders will output to usual target/out dirs and runners will run from them

## what installing a scenario looks like?

- sidenote: scenario process, running on the server, should control it's own render (even if it's embedded into game gui), so system only talks to one scneario process
- can installing a scenario mean spinning up a container?
- can scenario gui run in a separate tab? 
- can scenario server-side be a nodejs app? a jvm-app?
- so can scanerios be built as apps interacting with DeathStarGame apis
- if scenario is installed as a regular dep, deos it mean (require-ing) it in jvm builder and adding a :build target and compiling renderer in shadow-cljs builder?

## ~~yes, scenarios should be apps, spinned up in containers~~

- <s>we are already in docker
- sceanrio creaters should be elevated to building real apps
- when relying on apis, scenario dependencies and ideas stay even more free, with the feeling of building an appliaction, not jsut scripting, so the quality of scenarios will rise exponentially as more people will be willing and excited to really go for it with scenarios
- users should build apps that use DeathStarGame api or are used by it
- communicate bidirectionally over rsocket
- system and scenraios talk using data, each having its own runtime (system has several), giving natuaral isolation
- calrity and ease of development: we launch the system and then start/stop scneario app only, whereas system is always running as a whole and exposes only apis
- scnearios being apps of their own provide isolation, definitiveness of api, dependency freedom, decoupling of system and scnearios
- scenarios become true extensions, addons, or microservices to the system
- users creating scenraios build literally apps of their own, while system focuses on api communication over how-do-we-intergate-these-scripts (although we have docker and containers)
- should be possible to develop such scenario apps using the system itself
  - browser vscode would open a directory with such app's code (copied from a template directory from DeathStarGame repo)
  - system's shadow-cljs builder would add a build target and compile the app, expose nrepl, system would connect vscode to nrepl and spin up a container with this new scenario
  - now we have a repl into an app and see scenario's gui inside a tab (iframe)
  - we have a button that restarts the app container if needed (or posisbly even use VSCode's terminal into apps container, so user can restart themselves)
  - one we done, we can copy the code from the system on PC and put into a repo or smth</s>


## ~~sceanrio ui as iframe inside game ui~~

- <s>from user experience, we need to see player's scenario views and a combined view, meaning being able to switch between multiple small tabs (or open them alongide each other) inside single browser tab
- if scencario gui is an app, openable even in a standlone tab, it should be used by the as iframe</s>

<img height="512px" src="./svg/2020-11-01-iframes.svg"></img>


## installing scenarios: as namespaces

- sceanrios are simply code
- are developable only within the system, which is as it should be
- installing would mean 
  - copying files from a url into the app entity's filesystem
  - jvm app would compile(or even eval them) thus creating scenario's namespace
  - option A: ui builder would adds a new build target and compiles an app, which is used by iframe
  - option B: renderer code is directly sent by jvm-app to game-ui and evaled there

## scenario as a library: game forms the state on jvm and delivers to game-ui, which passes it to scenario renderers

- simulations run on jvm and new state is formed for that game in it's unique generated namespace
- and game passes it over its connection to game-ui and subsequently to sceanrio renderer
- as opposed to scenario updating its own renderers over unique connection
- why: game may choose to render that scenario multiple times and it should be in charge of that
- if so, than every such renderer cannot have a whole connection back to scenario app (otherwise there will be a connection for each tab rendering state of a particular player)
- or tabs for dev and latest game state for the player themselves
- point is: game should be free to render state multiple times and in a selective manner

## single container vs docker-compose: docker-compose

- since docker containers don't use much RAM and shared volume is a norm, docker-compose is a better tool and abstraction, than lower level bash scripting
- the size of the app installation (all images) does not matter, and on updates new layers will be downloaded faster

## step one: app entity contains just IPFS node and jvm-app, do data flow between peers

- this is the heart of the system


## installation/launch container

- no need for OS scripts, instead use a conatiner like a scrip ( with --rm flag , will exit after app is run)
- the container may need to be run as privileged (to be able to isntall docker app plugin), or not even, if with stack
- user runs this container, which in tern either installs docker app or uses docker stack to run the system
- it's a more powerful (we can use a ligit app inside, cljs nodejs for example, or even jvm) not just bash scripts
- user experience: just run one thing and game is up, run it again with --uninstall and it's down, run it again with --remove-volumes and that's done as well etc.


## player app eneities: identifying by port, localhost:PORT = docker-compose --project-name PORT

- so app's api/ui port also acts as an app name (or name prefix), to avoid ambiguity
- possible to encapsulate app under port ?

## installation/launch container part 2

- a privileged container that has api and can dynamically change files in sorce volume, so apps can be configured to comply to that one port
- a launch container is users/developers interface to the system: we basically put bash scripts and maybe programm api in there and can start/stop/configure system
- but: it's cross platform and versatile (a running program, not just script)
- it would also install docker app plugin or enable swarm

## how technically code evalution will work in the system

- [ palyers still need a REPL , but game state should be advancable, recreatable, syncable and independent of ui](https://github.com/sergeiudris/deathstar.lab/blob/4412eebce46dfad0f860276a2aa8d9c0e69c53c2/docs/deathstar.ltee/as-vscode-extension.md#state-its-about-state)
- [namepsaces, namespaces everywhere: namespaces can be discarded and re-created](https://github.com/sergeiudris/deathstar.lab/blob/4412eebce46dfad0f860276a2aa8d9c0e69c53c2/docs/deathstar.ltee/as-vscode-extension.md#how-to-def-namespaces-are-free)
- [discarding/creting copies of palyer's namespace in clojure](https://github.com/sergeiudris/deathstar.lab/blob/4412eebce46dfad0f860276a2aa8d9c0e69c53c2/docs/deathstar.ltee/as-vscode-extension.md#discardingcreting-copies-of-palyers-namespace-in-clojure)
- [simulation as f(state,code,time), why there is no need for cljs self-hosting](https://github.com/sergeiudris/deathstar.lab/blob/4412eebce46dfad0f860276a2aa8d9c0e69c53c2/docs/deathstar.ltee/as-vscode-extension.md#simulation-as-fstatecodetime-why-there-is-no-need-for-cljs-self-hosting)
- correction
  - code will be evaled on one mahcine - the host peer of that particular game : connected peers will send all the inputs and get eval results back
  - game simulations are run on the host peer as well (both main and test)
  - else the same: peers will get their unique namespace and copies of it, it's about creating/discarding namespaces, updating individual states (for rendering player's map) and running simultaions to advance the source of truth state of the game

## ipfs nodes, router loopback, docker compose network

- ipfs nodes (or any other apps) sometimes cannot connect due to router not supporting loopback (cannot dial your own WAN public ip)
- one approach would be to use some public ipfs node(s) that support pubsub and communicate through them, but this is fragile
- instead, make nodes able to discover/connect through docker-compose network, while keeping global ipfs node netwroking intact (by adding additional addresses to ~/.ipfs/config Addresses/Swarm
- this way, nodes can communicate locally, even offline, but would be able to connect to the game launched on another peer 

## peer conmmunication: connecting to peer vs pubsub grid - pubsub grid

- IPFS are working on making pubsub group-like: as in, peers would not particiapte in only global pubsub, but be able to join a certain group
- and they are making it more and more efficient by designing/applying new algorithms
- so looking forward, it means, that the peers of the game app would be able to form global sub-pubsub (even now it's possible with gloval pubsub)
- and would be able to exhcange data through it, as a single global app entity
- a peer would only need to connect to one other game peer and they are part of the app, can receive data
- that in principle allows us to think about data exchange (joining game, observing) as streams of data over pubsub, rather than direct connections of player peers to host peer
- however, for efficiency and speed and reducing network load, it could be better to play games peers-to-host, while doing queries and data sync over pubsub: so pubsub for everything, but a particular game via connecting
- or: a game could be a sub-sub-pubsub, so that observers can subscribe to that particular game
- with that in mind
  - when developing locally, instead of connecting to peer, go for autodiscover through mDNS (whatever that is) and forming a pubsub (global for now)

## in dev mode: be able to switch between circuit relay mode and local docker network with auto discovery

- it is awesome that communication over circuit relay just works out of the box
- but still, from design standpoint - elegance, sanity, it's peer-to-peer after all - locally launched nodes should auto discover and connect, even offline

## ipfs pubsib grid with rsocket protocol

- once peers are connected somehow, pubsub works
- what is needed is an rsocket abstraction over IPFS pubsub: be able to make p2p requests, bidirectional
  - behind the scenes, give messages id etc.

## ipfs: docker network autodiscovery, pubsub do work out-of-the-box 

- docker network autodiscovery,pubsub works out-of-the-box when on a single deafult network - nodes find each other, connect and pubsub - all just works
- docker networks probably need to be configured a bit more to allow named network auto discovery as well


## IPFS global pubsub allows for global game/player discovery staight away: it's like a radio, where app topic (and each game/event) is a frequency

- every peer will sub to the game topic: which should be like a frequency/channel
- every peer will have it's own db to store data from hosted games
- but peer's db will also store *global* lists : current players online, current games created
- when a peer creates a game, event will go into pubsub and every peer's db will update the list
- when a peer (or connected/sharing pubsub for the game peers) will query - they query one single db on the host peer's machine

## IPFS node pubsub stream cannot be consumed from jvm-app: either use libp2p or fork-modify js-ipfs node

- sadly, IPFS node's pubsub stream cannot be consumed from another app via node's API anyway...
- so basically it means either using libp2p inside an app or forking node and modifying it to expose pubsub stream via an API


## using libp2p instead of IPFS node

<img height="512px" src="./svg/2020-11-13-libp2p.svg"></img>

- jvm-libp2p?
- the app logic should ideally be decoupled from peer logic: when we restart app, we shouldn't drop connections or lose id
- in that sense, we need a node, but such that it allows us to consume and send pubsub 
- there are also things that IPFS node stores in files (peer id, settings) that we'd have to re-implement, although the goal is access to pubsub